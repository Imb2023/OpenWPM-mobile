{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.metrics.pairwise import pairwise_distances\n",
    "import matplotlib\n",
    "import shutil\n",
    "\n",
    "SILHOUETTE_DELTA = 0.01 \n",
    "\n",
    "HIGH_LEVEL_FEATURES = ['script_url','canvas_fingerprinting','canvas_font_fingerprinting', \\\n",
    "                       'audio_context_fingerprinting','webrtc_fingerprinting', \\\n",
    "                       'battery_fingerprinting','triggers_requests', \\\n",
    "                       'triggers_third_party_requests','easylist_blocked', \\\n",
    "                       'easyprivacy_blocked', 'disconnect_blocked', 'third_party_script','min_rank', \\\n",
    "                       'num_sites','num_sites_overall','category','country']\n",
    "\n",
    "PROB_THRES = 0.7\n",
    "BATCH_SIZE = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## classify misc labelled results \n",
    "def classification(data, labels, count, path, thres, limit=None):\n",
    "    #prepare data\n",
    "    misc = data['script_url'].as_matrix()\n",
    "    # drop higher level features \n",
    "    df = data.copy()\n",
    "    for i in HIGH_LEVEL_FEATURES:\n",
    "        df = df.drop(i, 1)\n",
    "    df = df.as_matrix()\n",
    "    clusters = np.copy(labels)\n",
    "    clf2 = RandomForestClassifier(n_estimators=100, max_features='auto') # sqrt(Num of feature to sample)\n",
    "    \n",
    "    print (\"Before classifying misc. samples: %d\" % len(np.where(clusters == -1)[0]))\n",
    "    f = np.hstack((np.double(df),np.vstack(clusters)))\n",
    "    misc = misc[np.where(f[:,-1] == -1)[0]]\n",
    "    X_train = f[f[:,-1] >= 0, 0:-1]\n",
    "    y_train = f[f[:,-1] >= 0, -1]\n",
    "    X_test = f[f[:,-1] == -1, 0:-1]\n",
    "    y_test = f[f[:,-1] == -1, -1]\n",
    "    clf2.fit(X_train, y_train)\n",
    "    res = clf2.predict(X_test)\n",
    "    prob = clf2.predict_proba(X_test)\n",
    "    max_prob = np.max(prob, axis=1) # only take the max prob value\n",
    "    for i in range(min(limit,len(prob))):\n",
    "        # threshold this can vary for diff feature compression and algorithm\n",
    "        ind = np.argmax(max_prob)\n",
    "        if max_prob[ind] > thres: \n",
    "            y_test[ind] = res[ind]\n",
    "            max_prob[ind] = 0.0 # replace the prob\n",
    "    clusters[clusters == -1] = y_test\n",
    "\n",
    "    sorted_label = map(lambda x: x, sorted(zip(misc, res, np.max(prob, axis=1)), key=lambda x: x[2], reverse=False))\n",
    "    df = pd.DataFrame(sorted_label)\n",
    "    df.to_csv(path+'/script_labels_prob_'+str(count)+'.csv', index=False, header=['url', 'pred', 'prob'])\n",
    "    print (\"After classifying misc. samples: %d\" % len(np.where(clusters == -1)[0]))\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plot per cluster silhouette coefficient\n",
    "def plot_clusterwise_silhouette(data, cluster_labels, widht, height, min_v, max_v):\n",
    "    matplotlib.rcParams['ps.useafm']=True\n",
    "    matplotlib.rcParams['pdf.use14corefonts']=True\n",
    "    matplotlib.rcParams['text.usetex']=True\n",
    "    #prepare data\n",
    "    df = data.as_matrix()\n",
    "        \n",
    "    # unique clusters\n",
    "    n_clusters = len(set(cluster_labels))\n",
    "    \n",
    "    plt.figure(figsize=(widht, height))\n",
    "    # get axis for plot\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    ax.set_xlim([min_v, max_v])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax.set_ylim([0, len(df) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(df, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    # withour clauster -1 (misc cluster)\n",
    "    inds = np.where(cluster_labels >= 0)[0]\n",
    "    silhouette_avg_nomisc = silhouette_score(df[inds,:], cluster_labels[inds])\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(df, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in sorted(set(cluster_labels)):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        if i >= 0:\n",
    "            ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "        else:\n",
    "            ax.text(0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    #ax.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax.axvline(x=silhouette_avg_nomisc, color=\"blue\", linestyle=\"-.\")\n",
    "    \n",
    "    ax.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax.set_xticks(np.arange(min_v, max_v+0.1, 0.2))\n",
    "    #plt.show()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## check if clusters can be combined without reducing too much of silhouette coefficient\n",
    "def pairwise_cluster_comparison(data, clusters):\n",
    "    pairwise_merge = {}\n",
    "    df = data.as_matrix()\n",
    "    unique_lables = sorted(set(clusters))\n",
    "    for i in unique_lables:\n",
    "        for j in unique_lables:\n",
    "            if i == j or i == -1 or j == -1:\n",
    "                continue\n",
    "            labels = np.copy(clusters) # restore original to make comparison   \n",
    "            labels[labels == j] = i\n",
    "            inds = np.where(labels >= 0)[0] # only properly clustered items\n",
    "            val = silhouette_score(df[inds,:], labels[inds])\n",
    "            pairwise_merge[(i,j)] = val\n",
    "    return pairwise_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## perform dbscan clustering \n",
    "def dbscan_cluster(data, e, s, m, a):\n",
    "    df = data.as_matrix()\n",
    "    ## cosine isn't directly supported \n",
    "    if  m == 'precomputed':\n",
    "        df = pairwise_distances(df, metric='cosine')\n",
    "    dbscan = DBSCAN(eps=e, min_samples=s, metric=m, algorithm=a)\n",
    "    dbscan.fit(df)\n",
    "    print  \"DBSCAN clusters: \",len(set(dbscan.labels_))\n",
    "    return dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## print smaples per cluster\n",
    "def print_cluster_freq(labels):\n",
    "    freq = Counter(labels)\n",
    "    print sorted(freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (509) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(405937, 514)\n"
     ]
    }
   ],
   "source": [
    "## main computation starts here\n",
    "feats = None\n",
    "pd.set_option(\"display.max_colwidth\",500)\n",
    "pd.set_option(\"display.max_rows\",500)\n",
    "feats = pd.read_csv('feature_file.csv', sep='\\t')\n",
    "print feats.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(916, 497)\n"
     ]
    }
   ],
   "source": [
    "interested_scripts=feats[(feats.addEventListener_devicelight == 1) |\n",
    "      (feats.addEventListener_devicemotion == 1) |\n",
    "      (feats.addEventListener_deviceorientation == 1) |\n",
    "      (feats.addEventListener_deviceproximity == 1) ]\n",
    "\n",
    "\n",
    "# drop higher level features \n",
    "interested_scripts_features = interested_scripts.copy()\n",
    "for i in HIGH_LEVEL_FEATURES:\n",
    "    interested_scripts_features = interested_scripts_features.drop(i, 1)\n",
    "    \n",
    "print interested_scripts_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN clusters:  39\n",
      "('For n_clusters =', 39, 'The average silhouette_score is :', 0.53928478469126995)\n"
     ]
    }
   ],
   "source": [
    "## Using distance metrics for boolean features like dice, jaccard, hamming distance\n",
    "labels = dbscan_cluster(interested_scripts_features, 0.1, 3, 'dice', 'auto') # may want to tweak the distance threshold\n",
    " \n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22\n",
    "       }\n",
    "\n",
    "matplotlib.rcParams['axes.titlesize'] = 40\n",
    "matplotlib.rcParams['axes.labelsize'] = 30  \n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "if os.path.isdir('Clustering_Result'):\n",
    "    shutil.rmtree('Clustering_Result')\n",
    "os.mkdir('Clustering_Result')\n",
    "\n",
    "plts = plot_clusterwise_silhouette(interested_scripts_features, labels, 15, 15, -0.8, 1)\n",
    "plts.tight_layout()\n",
    "plts.savefig('Clustering_Result/cluster_step1.pdf', format='pdf', dpi=1200)\n",
    "#plts.show()\n",
    "plts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label frequency\n",
      "[(-1, 216), (0, 71), (1, 174), (2, 3), (3, 12), (4, 46), (5, 12), (6, 6), (7, 71), (8, 10), (9, 8), (10, 13), (11, 9), (12, 8), (13, 6), (14, 10), (15, 4), (16, 30), (17, 16), (18, 15), (19, 5), (20, 27), (21, 18), (22, 4), (23, 3), (24, 3), (25, 9), (26, 17), (27, 19), (28, 5), (29, 5), (30, 14), (31, 12), (32, 6), (33, 10), (34, 4), (35, 5), (36, 6), (37, 4)]\n",
      "Round: 1\n",
      "[(24, 16), (16, 24)] 0.814422455212\n",
      "max avg_silhouette: 0.814422\n",
      "Merged cluster 24 with cluster 16\n",
      "[(-1, 216), (0, 71), (1, 174), (2, 3), (3, 12), (4, 46), (5, 12), (6, 6), (7, 71), (8, 10), (9, 8), (10, 13), (11, 9), (12, 8), (13, 6), (14, 10), (15, 4), (16, 33), (17, 16), (18, 15), (19, 5), (20, 27), (21, 18), (22, 4), (23, 3), (25, 9), (26, 17), (27, 19), (28, 5), (29, 5), (30, 14), (31, 12), (32, 6), (33, 10), (34, 4), (35, 5), (36, 6), (37, 4)]\n",
      "('For n_clusters =', 38, 'The average silhouette_score is :', 0.5385478969478662)\n",
      "Round: 2\n",
      "[(6, 2), (2, 6)] 0.811029919856\n",
      "max avg_silhouette: 0.811030\n",
      "Merged cluster 2 with cluster 6\n",
      "[(-1, 216), (0, 71), (1, 174), (3, 12), (4, 46), (5, 12), (6, 9), (7, 71), (8, 10), (9, 8), (10, 13), (11, 9), (12, 8), (13, 6), (14, 10), (15, 4), (16, 33), (17, 16), (18, 15), (19, 5), (20, 27), (21, 18), (22, 4), (23, 3), (25, 9), (26, 17), (27, 19), (28, 5), (29, 5), (30, 14), (31, 12), (32, 6), (33, 10), (34, 4), (35, 5), (36, 6), (37, 4)]\n",
      "('For n_clusters =', 37, 'The average silhouette_score is :', 0.53604321676235034)\n",
      "Round: 3\n",
      "[(37, 23), (23, 37)] 0.807557784999\n",
      "max avg_silhouette: 0.807558\n",
      "Merged cluster 23 with cluster 37\n",
      "[(-1, 216), (0, 71), (1, 174), (3, 12), (4, 46), (5, 12), (6, 9), (7, 71), (8, 10), (9, 8), (10, 13), (11, 9), (12, 8), (13, 6), (14, 10), (15, 4), (16, 33), (17, 16), (18, 15), (19, 5), (20, 27), (21, 18), (22, 4), (25, 9), (26, 17), (27, 19), (28, 5), (29, 5), (30, 14), (31, 12), (32, 6), (33, 10), (34, 4), (35, 5), (36, 6), (37, 7)]\n",
      "('For n_clusters =', 36, 'The average silhouette_score is :', 0.53351048935245082)\n",
      "Round: 4\n",
      "[(37, 35), (35, 37)] 0.803680126162\n"
     ]
    }
   ],
   "source": [
    "## Merge clusters based on silhouette coefficient, considering SILHOUETTE_DELTA as possible noise \n",
    "\n",
    "import matplotlib \n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22\n",
    "       }\n",
    "matplotlib.rcParams['axes.titlesize'] = 40\n",
    "matplotlib.rcParams['axes.labelsize'] = 30  \n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plts = None\n",
    "\n",
    "first_max = None\n",
    "last_max = None\n",
    "count = 1\n",
    "olabels = np.copy(labels)\n",
    "print (\"Original label frequency\")\n",
    "print_cluster_freq(olabels)\n",
    "while True:\n",
    "    print (\"Round: %d\" % count)\n",
    "    res = pairwise_cluster_comparison(interested_scripts_features, olabels)\n",
    "    last_max = max(res.values())\n",
    "    maxs = [i for i, j in res.items() if j == last_max]\n",
    "    print maxs, last_max\n",
    "    if first_max == None:\n",
    "        first_max = last_max\n",
    "    if first_max - last_max < SILHOUETTE_DELTA: #tolerating 5% as noise\n",
    "        print  (\"max avg_silhouette: %f\" % last_max)\n",
    "        largest_cluster = 0\n",
    "        selected = None\n",
    "        for x,y in maxs:\n",
    "            f1 = len(np.where(olabels == x)[0])\n",
    "            f2 = len(np.where(olabels == y)[0])\n",
    "            if largest_cluster < max(f1, f2):\n",
    "                if f1 > f2:\n",
    "                    selected = (x, y)\n",
    "                else:\n",
    "                    selected = (y, x)\n",
    "                largest_cluster = max(f1, f2)\n",
    "        olabels[olabels == selected[1]] = selected[0]\n",
    "        print (\"Merged cluster %d with cluster %d\" %(selected[1],selected[0]))\n",
    "        print_cluster_freq(olabels)\n",
    "        plts = plot_clusterwise_silhouette(interested_scripts_features, olabels, 15, 15, -0.8, 1)\n",
    "    else:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "plts.tight_layout()\n",
    "plts.savefig('Clustering_Result/cluster_step2.pdf', format='pdf', dpi=1200)\n",
    "#plts.show()\n",
    "plts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1\n",
      "Before classifying misc. samples: 216\n",
      "After classifying misc. samples: 211\n",
      "Round: 2\n",
      "Before classifying misc. samples: 211\n",
      "After classifying misc. samples: 206\n",
      "Round: 3\n",
      "Before classifying misc. samples: 206\n",
      "After classifying misc. samples: 201\n",
      "Round: 4\n",
      "Before classifying misc. samples: 201\n",
      "After classifying misc. samples: 196\n",
      "Round: 5\n",
      "Before classifying misc. samples: 196\n",
      "After classifying misc. samples: 192\n",
      "Round: 6\n",
      "Before classifying misc. samples: 192\n",
      "After classifying misc. samples: 191\n",
      "Round: 7\n",
      "Before classifying misc. samples: 191\n",
      "After classifying misc. samples: 190\n",
      "Round: 8\n",
      "Before classifying misc. samples: 190\n",
      "After classifying misc. samples: 190\n",
      "('For n_clusters =', 36, 'The average silhouette_score is :', 0.54561983792195601)\n"
     ]
    }
   ],
   "source": [
    "## see if the misc. samples (labelled as -1) can be classified as one of the other clsuters with high probability\n",
    "## Random Forest classifiers (with reduced feature sampling) can potentially be more robust to variance \n",
    "## here we consider classification prob >= 0.7 (may want to tweak this parameter) and we insert data in batches of 5 \n",
    "\n",
    "rlabels = np.copy(olabels)\n",
    "final_label = None\n",
    "count = 1\n",
    "while True:\n",
    "    print (\"Round: %d\" % count)\n",
    "    nlabels = classification(interested_scripts, rlabels, count, 'Clustering_Result', 0.8, BATCH_SIZE)\n",
    "    if np.array_equal(nlabels, rlabels):\n",
    "        final_label = rlabels\n",
    "        break\n",
    "    else:\n",
    "        rlabels = nlabels\n",
    "    count += 1\n",
    "    \n",
    "## final clustering results\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22\n",
    "       }\n",
    "matplotlib.rcParams['axes.titlesize'] = 40\n",
    "matplotlib.rcParams['axes.labelsize'] = 30  \n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plts = plot_clusterwise_silhouette(interested_scripts_features, final_label, 15, 15, -0.8,1)\n",
    "plts.tight_layout()\n",
    "plts.savefig('Clustering_Result/cluster_step3.pdf', format='pdf', dpi=1200)\n",
    "#plts.show()\n",
    "plts.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
